{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><font color='blue'>TAREA FINAL</font></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Construiremos un clasificador de imágenes usando el modelo pre-entrenado VGG16 y compararemos su performance con el ResNet50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Tabla de contenido\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>    \n",
    "\n",
    "1. <a href=\"#item41\">Descargar los datos\n",
    "2. <a href=\"#item42\">Parte 1</a>\n",
    "3. <a href=\"#item43\">Parte 2</a>  \n",
    "4. <a href=\"#item44\">Parte 3</a>  \n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"item41\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('concrete_data_week4.zip', <http.client.HTTPMessage at 0x1f26e331d30>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the data\n",
    "#!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip\n",
    "\n",
    "import urllib.request\n",
    "url = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week4.zip'\n",
    "filename = 'concrete_data_week4.zip'\n",
    "urllib.request.urlretrieve(url, filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip concrete_data_week3.zip\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile('concrete_data_week4.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de descomprimir los datos verá que los mismos ya han sido divididos en conjuntos de entrenamiento, validación y tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"item42\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diseñaremos un clasificador usando el modelo pre-entrenado VGG16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos el clasificador como sigue:\n",
    "\n",
    "1. Importaremos las librerías, módulos y paquetes necesarios. En particular importaremos *preprocess_input* desde <code>keras.applications.vgg16</code>.\n",
    "2. Usaremos un tamaño de lote de 100 imágenes tanto para entrenamiento como para validación.\n",
    "3. Construiremos un ImageDataGenerator para los conjuntos de entrenamiento y validación. VGG16 fue entrenado originalmente con imágenes 224x224, recordaremos esto al crear las instancias ImageDataGenerator.\n",
    "4. Crearemos un modelo secuencial. Le agregaremos VGG16 al modelo y un una capa densa.\n",
    "5. Compilaremos el modelo usando el optimizador adam y la categorical_crossentropy como función de pérdida.\n",
    "6. Ajustaremos el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imoport libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.applications import ResNet50,vgg16,VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "num_classes = 2\n",
    "image_resize = 224\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n",
      "Found 9501 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# image data generator train and validation\n",
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "#\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week4/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')\n",
    "#\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week4/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 8s 0us/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "model = Sequential()\n",
    "model.add(VGG16(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.layers\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-e18b41848c98>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/2\n",
      "301/301 [==============================] - 5666s 19s/step - loss: 0.2339 - accuracy: 0.9227 - val_loss: 0.0357 - val_accuracy: 0.9921\n",
      "Epoch 2/2\n",
      "301/301 [==============================] - 6140s 20s/step - loss: 0.0270 - accuracy: 0.9938 - val_loss: 0.0198 - val_accuracy: 0.9956\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2\n",
    "#\n",
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_vgg16_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"item43\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluaremos los modelos sobre los datos de test. Haremos lo siguiente:\n",
    "\n",
    "1. Cargaremos el modelo ResNet50 que construimos en el lab anterior.\n",
    "2. Construiremos un ImageDataGenerator para el conjunto de test. Para esta instancia, solamente debe pasársele el directorio de las imágenes de test, el target_size y el parámetro **shuffle** debe establecerse en False.\n",
    "3. Usaremos el método **evaluate_generator** para evaluar los modelos sobre los datos de test, pasando el ImageDataGenerator anterior como argumento.\n",
    "4. Imprimiremos la performance del clasificador usando el modelo pre-entrenado VGG16.\n",
    "5. Imprimiremos la performance del clasificador usando el modelo pre-entrenado ResNet50.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model(\"classifier_resnet_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator for the test set\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week4/test',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-95e22d26b287>:2: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n"
     ]
    }
   ],
   "source": [
    "# VGG 16\n",
    "aux = model.evaluate_generator(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.017 - acc: 0.996\n"
     ]
    }
   ],
   "source": [
    "print(\"loss: %.3f - acc: %.3f\" % (aux[0], aux[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux2 = saved_model.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.002 - acc: 1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"loss: %.3f - acc: %.3f\" % (aux2[0], aux2[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"item44\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predeciremos si las imágenes de test tienen grietas o no. Haremos lo siguiente:\n",
    "\n",
    "1. Usaremos el método **predict_generator** para predecir la clase de las imágenes en el conjunto de test, pasando la instancia ImageDataGenerator de los datos de test definida previamente.\n",
    "\n",
    "2. Reportaremos las predicciones de las primeras 5 imágenes. Imprimiremos algo como esto:\n",
    "\n",
    "<center>\n",
    "    <ul style=\"list-style-type:none\">\n",
    "        <li>Positive</li>  \n",
    "        <li>Negative</li> \n",
    "        <li>Positive</li>\n",
    "        <li>Positive</li>\n",
    "        <li>Negative</li>\n",
    "    </ul>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-06ac0a883269>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\\\n",
    "\n",
    "predicted_class=np.argmax(predict,axis=1)\n",
    "for i in range(0,5):\n",
    "    if predicted_class[i] == 0:\n",
    "        print('Negative')\n",
    "    else:\n",
    "        print('Positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RESNET50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictResnet = saved_model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "predicted_classResnet=np.argmax(predictResnet,axis=1)\n",
    "for i in range(0,5):\n",
    "    if predicted_classResnet[i] == 0:\n",
    "        print('Negative')\n",
    "    else:\n",
    "        print('Positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
